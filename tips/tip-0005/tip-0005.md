# TIP 0005: Hash Function

| TIP            | 0005                                             |
|:---------------|:-------------------------------------------------|
| authors:       | Alan Szepieniec and Alexander Lemmens and Ferdinand Sauer and Bobbin Threadbare |
| title:         | Tip5 Hash Function                                    |
| status:        | request for comments                                 |
| created:       | 2022-11-17                                       |
| issue tracker: | [161](https://github.com/TritonVM/triton-vm/pull/161) |
| pdf:           | [pdf](tip5-paper.pdf)                     |

**Abstract.**
This note proposes a new arithmetization-oriented hash function. It uses the SHARK design strategy [1] in combination with lookup tables, and is defined over the field with $p=2^{64}-2^{32}+1$ elements. This note also discusses techniques for efficiently arithmetizing the hash function.

## Introduction

In the space of arithmetization-oriented hash function, two design strategies stand out.

 1. The Marvellous design strategy [2], best known for its member Rescue-Prime [3], introduced the idea of alternating S-box layers where even layers compute low-degree permutations in one direction and odd layers compute low-degree permutations in the opposite direction. As a result, a small number of rounds guarantees that the algebraic degree of the cipher is sufficiently high when attacked from any direction. Moreover, in the specific case of Rescue-Prime, two consecutive S-box layers can be folded together into one low-degree arithmetization. This folding technique yields essentially two rounds of the cipher for the price of one cycle in the arithmetic virtual machine. Since the publication of the Marvellous design strategy, there has been very little progress in cryptanalyzing Rescue and Rescue-Prime.

 2. Reinforced Concrete [4] introduced the use of lookup tables in an otherwise arithmetization-oriented cipher. The lookup table can be evaluated efficiently on CPUs as well as proven efficiently in a zero-knowledge or succinctly verifiable proof system using Plookup [5] or techniques derived from there. Moreover, represented as polynomials over a finite field, non-trivial lookup tables have maximal degree. Therefore, the use of lookup tables provides a robust way to resist algebraic attacks including attacks relying on Gröbner bases. The downside of this technique is that the lookup tables cannot be too large; that therefore the field elements must be decomposed into chunks which are then looked up; and that the prover must establish the correct decomposition and recomposition of these chunks. This process leads to an expensive arithmetization and does not generalize well to arbitrary fields.

This note proposes a new hash function. It uses the SHARK design strategy, on which Marvellous is based, of using full S-box layers interleaved with MDS matrices. The S-boxes come in two types. The first is built from a table lookup that computes the cube map in $\mathbb{F}_{2^{8}+1}$ but offset by one. In addition to being fast to compute, this function makes the algebraic degree large and provides resistance against Gröbner basis attacks. The second type is the regular forward $\alpha$ th power map found in Rescue and Poseidon. As the second type of S-boxes constitutes the majority in every S-box layer, they suffice to provide defense against statistical attacks through the wide-trail argument.

This note also includes an arithmetization of the hash function in the STARK context. This arithmetization includes a novel lookup argument, which can be seen as lifting that of Haböck [7] to the appropriate context.

*Acknowledgements.* Many of the ideas used in this note came were first discussed in the course of the Rescue-Prime Optimization project [6].

## Specification

### Basic Parameters 

| Parameter | Symbol | Value |
|-----------|--------|-------|
| field modulus | $p$ | $2^{64} - 2^{32} + 1$ |
| number of rounds | $N$ | 5 |
| state size | $m$ | 16 |
| sponge rate | $r$ | 10 |
| sponge capacity | $c$ | 6 |
| digest length | $d$ | 5 |
| power map exponent | $\alpha$ | 7|
| number of split-and-lookups per round | $s$ | 4 |

For the sake of genericity the rest of the note uses the symbol rather than the value.

### S-Box

There are two types of S-boxes. One is the regular forward $\alpha$-th power map already used in Rescue-Prime. Denote this map by $T : x \mapsto x^\alpha$. For the field with $2^{64} - 2^{32} + 1$ elements, $\alpha = 7$.

The other type is more involved and may be called the split-and-lookup map. Every round consists of one S-box layer; in this layer the first $s$ state elements are mapped by the split-and-lookup map and the second $m-s$ state elements are mapped by the forward $\alpha$-th power map.

The split-and-lookup map is defined as follows:

$$ S : \mathbb{F}_p \rightarrow \mathbb{F}_p,  x \mapsto R^{-1} \cdot \rho \circ L^8 \circ \sigma  (R \cdot x) $$

The components are:

 - $R$ is the field element congruent to $2^{64}$ modulo $p$, accounting for native representation of field elements in Montgomery form.
 - $\sigma : \mathbb{F}_p \rightarrow \mathbb{F}_p^8, x \mapsto (a, b, c, d, e, f, g, h)$ where all outputs are at most 8 bits wide and $x = a + 2^{8} \cdot b + 2^{16} \cdot c + 2^{24} \cdot d + 2^{32} \cdot e + 2^{40} \cdot f + 2^{48} \cdot g + 2^{56} \cdot h$.
 - $L : \mathbb{F}_ p \rightarrow \mathbb{F}_ p$ is defined only for field elements that are at most 8 bits wide. Identifying this subset of $\mathbb{F}_ p$ with $\mathbb{F}_ {2^{8}+1}$, the lookup table $L$ computes $L : \mathbb{F}_ {2^{8}+1} \rightarrow \mathbb{F}_ {2^{8}+1}, x \mapsto (x+1)^3-1$.
 - $\rho : \mathbb{F}_ p^8 \rightarrow \mathbb{F}_ p$ computes the inverse of $\sigma$.

The inverse of this S-box is $x \mapsto R \cdot \rho \circ (L^{-1})^4 \circ \sigma (R^{-1} \cdot x)$.

One input-output pair is noteworthy $S(-1) = -1$.

### Remaining Specifications

A single round consists of three steps:

 1. A full S-box layer, in which the first $s$ elements are mapped by $S$ and the next $m-s$ elements by $T$.
 2. Matrix-vector multiplication of the MDS matrix with the state (as the column vector). The MDS matrix is circulant, giving rise to fast matrix-vector products. When $m=16$, the MDS matrix is the one given by the first row: `[18446742626305572865, 12103477672291081763, 2060678330275253760, 2379906257383880660, 13229869363167232, 12103947580051285184, 3631871650260640512, 18375880622847003104, 18446743700047396865, 7491684177549991903, 16328081945490043393, 11603770461046470701, 18433515290973110273, 5185371269165997376, 14872856315882446081, 4542937756286289441]`.
 3. Addition of constants. A preselected random constant is added into every element of the state.

The constants are determined by concatenating the byte $i$ (for the $i$ th constant, starting from zero) to the ASCII string "`Tip5`", hashing the string of 5 bytes using Blake3, taking the first 16 bytes of the digest, interpreting them as an integer in least-significant-byte-first order, reducing the integer modulo $p$, and multiplying the resulting field element by $R^{-1}$ which is the inverse of $2^{64}$ modulo $p$. This process is repeated $mN$ times to get as many round constants. The $(mi + j)$ th constant is used for the $j$ th state element in the $i$ th round.

The permutation $P$ consists of $N$ rounds. The hash function is obtained by instantiating the sponge construction with the permutation $P$ and truncating the output to length $d$.

The hash function comes in two modes of operation, depending on whether the input is fixed-length or variable-length.

 - When the input is fixed length (and in this case the length is always exactly $r = 10$), all capacity elements are initialized to 1. There is no need to pad the input. There is only one absorption.
 - When the input is variable-length, it is padded by appending a 1 followed by however many 0's as are necessary to make the padded input length a multiple of $r$. The capacity is initialized to all zeros and the input is absorbed over multiple iterations.

## Implementation Aspects

### Montgomery Representation

A field element $a \in \mathbb{F}_p$ is represented as the integer $\bar{a} \in \{0, \ldots, p-1\}$ congruent to $a \cdot R$ modulo $p$, where $R = 2^{64}$. The benefit of this representation is a faster multiplication algorithm: the product $c = ab$ is calculated by first calculating the integer product $\bar{a} \cdot \bar{b}$ and following this up with *Montgomery reduction*, which sends $\bar{a} \cdot \bar{b}$ to $\bar{c}$. We refer to Pornin's explanation [8] for a concise but comprehensive overview of Montgomery representation of elements in this field.

The split-and-lookup S-box anticipates the use of Montgomery representation. Specifically, the S-box 

$$ S : \mathbb{F}_p \rightarrow \mathbb{F}_p,  x \mapsto R^{-1} \cdot \rho \circ L^8 \circ \sigma  (R \cdot x) $$

becomes 

$$ S' : \mathbb{F}_p \rightarrow \mathbb{F}_p,  x \mapsto \rho' \circ L^8 \circ \sigma'  (x) $$

where $\sigma'$ decomposes the integer $\bar{a}$ into raw bytes, and $\rho'$ recomposes the raw bytes accordingly.

### MDS Matrix Multiplication

In the linear step, the state vector $\mathbf{x}$ is sent to $M \mathbf{x}$ where $M$ is the circulant MDS matrix. Rather than computing this matrix-vector product using $n^2$ multiplications, it pays to transform the arguments to the NTT domain and compute an element-wise product multiplication there, before transforming back. Specifically, let $\mathbf{v}$ be the first column of the MDS matrix. Then the map

$$ \mathbf{x} \mapsto M \mathbf{x} $$

is equivalent to

$$ \mathbf{x} \mapsto \mathsf{NTT}^{-1} (\mathsf{NTT}(\mathbf{v}) \circ \mathsf{NTT}(\mathbf{x})) , $$

where $\circ$ denotes the Hadamard (element-wise) product.

Furthermore, the inverse NTT is essentially the same as the forward NTT except using the *inverse* of the $m$ th root of unity, and except for the scaling by $m^{-1} \in \mathbb{F}_p$. By absorbing this scaling factor into $\mathbf{v}$ we get

$$ \mathbf{x} \mapsto \mathsf{NTT}(\mathsf{NTT}(m^{-1} \mathbf{v}, \omega) \circ \mathsf{NTT}(\mathbf{x}, \omega), \omega^{-1}) ,$$

where $\omega$ is the primitive $m$ th root of unity relative to which the NTTs are calculated.

Furthermore, following Longa and Naehrig [9], efficient implementations the NTT separate it into two steps. One step applies the butterfly operations, and another step reorders the elements in the vector according to the bitwise reverse of their index. These steps can come in either sequence. Let $\mathsf{NTT}^* $ and ${}^* \mathsf{NTT}$ denote the butterfly steps and $\mathsf{BR}$ the bit-reverse step, then

$$ \mathsf{NTT} = \mathsf{NTT}^* \circ \mathsf{BR} = \mathsf{BR} \circ {}^*\mathsf{NTT} .$$

Using these butterflies, two bit-reverse steps can be canceled. This gives the following map for the linear step of the round function:

$$ x \mapsto \mathsf{NTT}^* ({}^* \mathsf{NTT}(m^{-1} \mathbf{v}, \omega) \circ {}^* \mathsf{NTT}(\mathbf{x}, \omega), \omega^{-1}) . $$

Note that the vector ${}^*\mathsf{NTT}(m^{-1} \mathbf{v}, \omega)$ ought to be precomputed. The matrix $M$ was chosen such that this vector is (abusing set-builder notation to build vectors instead of sets)

$$ (R^{-1} \cdot 2^i | i \in (4, 1, 4, 3, 3, 7, 0, 5, 1, 5, 0, 2, 6, 2, 4, 1) ) . $$

As a result, the Hadamard multiplication conssits of a bunch of bit shifts followed by Montgomery reduction.

Here is a test vector: using $\omega = 17293822564807737345$, the random vector `[5735458159267578080, 11079291868388879320, 7126936809174926852, 13782161578414002790, 164785954911215634, 3118898034727063217, 6737535956326810438, 5144821635942763745, 16200832071427728225, 8640629006986782903, 11570592580608458034, 2895124598773988749, 3420957867360511946, 5796711531533733319, 5282341612640982074, 7026199320889950703]` is mapped to `[4104170903924047333, 6387491404022818542, 14981184993811752484, 16496996924371698202, 5837420782411553495, 4264374326976985633, 5211883823040202320, 11836807491772316903, 8162670480249154941, 5581482934627657894, 9403344895570333937, 8567874241156119862, 15302967789437559413, 13072768661755417248, 18135835343258257325, 9011523754984921044]`.

## Lookup Argument

The lookup argument  establishes that the values appearing on the trace non-deterministically were in fact integrally looked up. It consists of two independent components. First is an argument for proving that two given vectors satisfy a subset relation (as sets). This primitive is presented in two steps: the intuition and security is articulated in terms of a Bézout relation, whereas the concrete construction works in terms of logarithmic derivatives. This subset argument is used in several places in the second component, which is the cascade construction. Its purpose is to break down large lookup tables into smaller ones, benefiting the overall arithmetic complexity. After describing these components we put everything together for a concrete arithmetization of Tip5, lookup gates an all.

### Bézout Argument

The subset argument is a cross-table argument between two tables, which for the sake of genericity are called the *server* and the *client*. The The client table contains a list of input-output pairs with repetitions and in an arbitrary order. The server table lists *all possible* input-output pairs. The argument establishes that as sets, the client's input-output pairs are a subset of those of the server.

Using random weights from the verifier `a, b`, the input and output columns are compressed into one random linear combination. It then suffices to show that the set of random linear combinations of the client, is a subset of the random linear combinations of the server.

Let $\lbrace \texttt{rlc}_i \rbrace_i$ denote the set of input-output pairs, each compressed into a random linear combination sing `a` and `b`, that are looked up at least once. The client and server tables both define a product polynomial whose factors are random linear combinations offset by $X$.

$$ \texttt{rpc}(X) = \prod_i (\texttt{rlc}_i - X)^{m_i} $$

$$ \texttt{rps}(X) = \prod_i (\texttt{rlc}_i - X) $$

The difference between these two polynomials is the multiplicities $m_i$ of their roots, which is 1 for the Lookup Table and possible greater than 1 for the Hash Table. The letter `r` suggests that these values of these polynomials in $\alpha$ can be computed by *running product* columns, once $\alpha$ is known. But merely comparing the values $\texttt{rpc}(\alpha)$ and $\texttt{rps}(\alpha)$ does not suffice – the multiplicities of the roots are different.

The following Bézout relation argument eliminates these multiplicities, enabling a test for subset relationship by probing a polynomial identity in the random point $\alpha$.

In addition to a *running product*, the client table defines a *formal derivative*. Let $\texttt{fdc}(X)$ denote this polynomial:

$$ \texttt{fdc}(X) = \sum_i m_i (X - \texttt{rlc}_i)^{m_i - 1} \prod_{j \neq i} (X - \texttt{rlc}_j)^{m_j} = \frac{d}{dX} \texttt{rpc}(X) $$

Likewise, the server table defines a formal derivative as well, except this one is weighted by multiplicity:

$$ \texttt{mwfds}(X) = \sum_i m_i \prod_{j \neq i} (X - \texttt{rlc}_j) $$

On the side of the client, the running product and its formal derivative satisfy the following Bézout relation: $\texttt{rpc}(X) \cdot x(X) + \texttt{fdc}(X) \cdot y(X) = g(X)$, where $g(X)$ is the greatest common divisor and $x(X)$ and $y(X)$ are Bézout coefficient polynomials. Then $\frac{\texttt{rpc}(X)}{g(X)}$ is the square-free polynomial with the same roots as $\texttt{rpc}(X)$, and equal to $\texttt{rps}(X)$ of the server. Moreover, a similar relationship holds for the formal derivatives: $\frac{\texttt{fdc}(X)}{g(X)} = \texttt{mwfds}(X)$. By eliminating $g(X)$ we get the identity of polynomials $\texttt{rpc}(X) \cdot \texttt{mwfds}(X) = \texttt{fdc}(X) \cdot \texttt{rps}(X)$. The objective is to test this identity in the random point $\alpha$.

The cheating prover who uses an input-output pair not present in the server table must use a polynomial $\texttt{rpc}(X)$ with at least one root that $\texttt{rps}(X)$ does not share. As a result, the polynomial identity is not satisfied because this root occurs in the left hand side with multiplicity one greater than in the right hand side. By the Schwarz-Zippel lemma, the probability that the identity holds in the random point $\alpha$ is at most $\frac{(1 + m/2) T}{|\mathbb{F}|}$, where $T$ is the padded height of the table.

### Optimization with Logarithmic Derivatives

The above intuition gives rise to an AET and AIR for checking it. Indeed, the values `rpc(α)`,`fdc(α)`, `rps(α)`, and `mwfds(α)` can all be computed via running accumulator columns. However, it turns out there is an optimization that reduces the number of columns at the expense of a batch-inversion. This optimization is inspired by Haböck's lookup argument [7] but ultimately that argument is tailored to Multilinear IOPs. The present optimization can be seen as lifting that technique to the AET/AIR setting, albeit derived differently.

The logarithmic derivative of a polynomial $f(X)$ is defined as $\frac{f'(X)}{f(X)}$. The logarithmic derivative is so named because the logarithmic derivative of the product of two polynomials is the sum of their logarithmic derivatives: $\frac{\mathsf{d}(f(X)g(X))}{f(X)g(X)\mathsf{d}X} = \frac{f'(X)g(X)}{f(X)g(X)} + \frac{f(X)g'(X)}{f(X)g(X)} = \frac{f'(X)}{f(X)} + \frac{g'(X)}{g(X)}$.

Observe that the polynomial identity

$$ \texttt{rph}(X) \cdot \texttt{mwfdl}(X) = \texttt{fdh}(X) \cdot \texttt{rpl}(X) $$

can be re-written in terms of logarithmic derivatives:

$$ \frac{\texttt{fdc}(X)}{\texttt{rpc}(X)} = \frac{\texttt{mwfds}(X)}{\texttt{rps}(X)} = \sum_i \frac{m_i}{X - \texttt{rlc}_i} .$$

On the side of the server, two columns are needed to probe this identity in the random point $\alpha$.

 - the running product `rps` and multiplicity-weighted formal derivative `mwfds` are merged into the single extension column `sum`, which contains the running sum of `mul / (α - rlc)`;
 - base column `mul` contains the multiplicity with which the given row is queried.

On the client only *one* extension column is needed. Specifically, the running product `rpc` and formal derivative `fdc` are merged into a single column, the logarithmic derivative `ldc`.

To update `ldc`, recall that the standard running product column `rpc` is defined to accumulate one *factor* in every row. Moreover, `ldc` is defined to contain the logarithmic derivative of `rpc` in every row, so we can use the eponymous property to populate it. Speficially, the would-have-been running product update rule `rpc* = rpc ⋅ (α - rlc*)` becomes `ldc* = ldc + 1/(α - rlc*)`, where the asterisk `*` indicates the respective element from the next row.

The update rules `sum* = sum + mul* / (α - rlc*)` and `ldc* = ldc + 1 / (α - rlc*)` can be converted to AIR constraints by multiplying left and right hand sides by `(α - rlc*)`.

### Cascade Construction

The cascade construction arithmetizes a composite lookup gate in terms of multiple lookups into component gates followed by combining the looked-up outputs. For example, supose that a 16-bit wide map can be represented as the concatenation of two 8-bit wide lookups. Then this 16-bit wide map can be arithmetized with a cascade table as follows. The cascade table is the *server* authenticating 16-bit wide input-output pairs to the external client. Internally, every input or output element is represented as two limbs of 8 bits. To authenticate the 8-bit wide input-output pairs, the cascade table is the *client* of an 8-bit wide subset argument with an external server.

A cascade table consists of 5 base columns and 3 extension column. The extension columns are defined relative to challenges `a,b,c,d,β,γ`. The Latin letters denote weights used to compress columns, and the Greek letters denote indeterminates.

The base columns are

 - `lkinhi` and `lkinlo`, the high and low limbs of the lookup input;
 - `lkouthi` and `lkoutlo`, the high and low limbs of the lookup output;
 - `mul`, the multiplicity with which the given row is being queried by the external client.

The extension columns are

 - `sum`, which contains the running sum of inverses;
 - `ldhi` and `ldlo`, the running logarithmic derivatives of the high and low input-output pairs.

The AIR constraints can be inferred from the section about the Bezout relation argument and its optimization in terms of logarithmic derivatives. Note that when the cascade table is wearing the server hat, the random linear combinations are given by

$$ \mathtt{rlc} = 2^{w} \cdot a \cdot \mathtt{lkinhi} + a \cdot \mathtt{lkinlo} + 2^{w} \cdot b \cdot \mathtt{lkouthi} + b \cdot \mathtt{lkoutlo} , $$

where $w$ is the width (in bits) of each limb. When the cascade table is wearing the client hat, the random linear combinations are given by

$$ \mathtt{rlc} = c \cdot \mathtt{lkinhi} + d \cdot \mathtt{lkouthi} $$

and

$$ \mathtt{rlc} = c \cdot \mathtt{lkinlo} + d \cdot \mathtt{lkoutlo}. $$

To see why the construction is sound, suppose a malicious prover attempts to prove that a pair $(\mathtt{lkin}^*, \mathtt{lkout}^*)$ belongs to the wide lookup relations when it does not. Then either the cascade table contains a corresponding row $(\mathtt{lkinhi}^*, \mathtt{lkinlo}^*, \mathtt{lkouthi}^*, \mathtt{lkoutlo}^*, \mathtt{mul})$, *i.e.*, such that $\mathtt{lkin}^* = 2^w \cdot \mathtt{lkinhi}^* + \mathtt{lkinlo}$ and $\mathtt{lkout}^* = 2^w \cdot \mathtt{lkouthi}^* + \mathtt{lkoutlo}$ and $\mathtt{mul} \neq 0$; or the cascade table does not contain such a corresponding row. The latter case implies a failure of the client-cascade subset argument. The probability of this event is bounded by the soundness error of the subset argument. The former case implies one of two propositions:

 1. The server table for the narrow lookup contains a row $(\mathtt{lkinhi}^*, \mathtt{lkouthi}^*, \mathtt{mul})$ with $\mathtt{mul} \neq 0$.
 2. The server table for the narrow lookup contains a row $(\mathtt{lkinlo}^*, \mathtt{lkoutlo}^*, \mathtt{mul})$ with $\mathtt{mul} \neq 0$.

The propositions cannot both be true because that would imply that $(\mathtt{lkin}^*, \mathtt{lkout}^*)$ does satisfy the relation defined by the wide lookup. Therefore, one or both of these propositions must be false, implying at least one violation of the cascade-server subset argument. Once again, the probability of this event is bounded by the soundness error of the subset argument.

It is possible to arrange multiple cascade tables in a, well, *cascade*. This enables the decomposition of very large composite lookup maps into tiny components. The tradeoff is that the number of rows can increase by up to a factor two for every cascade level. However, as the tables get narrower they start becoming saturated faster. For instance, an 8-bit wide lookup table can only hold 256 rows.

## Arithmetization of Tip5 Hash Function

After committing to the base column, the prover obtains random challenges from the verifier (or from Fiat-Shamir). The challenges used here are $a, b, c, d, \beta, \gamma, \delta$.

There are three tables in total: the hash table, the 16-bit wide cascade table, and the 8-bit wide lookup table. The hash table looks up $s \times 4$ input-output pairs of 16 bits in the cascade table, and the cascade table looks up the low and high limbs in the 8-bit wide lookup table. The relations between the hash table and other tables, as well as the columns and constraints that effect them, are out of scope for this note.

### Hash Table

Since $N = 5$ is not one less than a power of two, complicating arithmetic somewhat. By using 8 rows for every hash invocation, we can leverage periodic zerofiers. As a result, consistency or transition constraints can be activated or deactivated on rows congruent to $j$ mod 8, for any $j$.

A regular zerofier is the lowest-degree monic polynomial that sends a subgroup $H$ to zero. When this subgroup $H \subset \mathbb{F}^*$ has order $N$, this polynomial is given by $Z_H(X) = X^N - 1$. Let $\omega$ be a primitive 8th root of unity. The periodic zerofier $Z(X) = X^{N/8}-1$ maps every 8th element of $H$ to zero starting at $1 = \omega^0$ and $Z_H(\omega^{-i} \cdot X)$ does the same but starting at $\omega^i$.

Every lookup-input and every lookup-output must be explicitly represented. So $s$ field elements being mapped by the split-and-lookup S-box turn into $4 \cdot 2 \cdot s$ columns. Let `lkin[i]` and `lkout[i]` with `i in {0, ..., 4s-1}` denote these columns. For each pair `(lkin[i], lkout[i])` there is 1 extension column, `ldh[i]`, which accumulates a logarithmic derivative update.

The columns are as follows:

 - `pad` indicates whether the row is a padding row or not.
 - `lkin[4⋅i+j]`, `lkout[4⋅i+j]`, and `ldh[4⋅i+j]` for `j in [0,1,2,3]` and `i in [0,1,2,3]` for the `4` = $s$ state elements that are being split (into 8 pieces each) and looked up.
 - `st[i]` for `i in [4,5,6,7,8,9,10,11,12,13,14,15]` for the 12 remaining state elements that are mapped by the forward alpha power map.
 - `lkininv[i]` for `i in [0,1,2,3]` which contains the inverse-or-zero needed to establish the unique decomposition of the field element into 16-bit chunks.

 The rest of this arithmetization makes reference to `const[i]` for `i in [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]` for the round constants. These can be conceived of as columns but in practice it is more efficient to implement them via periodic interpolants.

The total number of columns is therefore 61. Of these 61 columns, 45 are base columns and 16 are extension columns.

*Initial constraints.*

 1. The very first logarithmic differential starts off having accumulated the first update: `ldh[0] ⋅ ( γ - a⋅lkin[0] - b⋅lkout[0] ) - 1`.

*Consistency constraints.* 

 1. The padding indicator is 0 or 1: `pad ⋅ (1 - pad)`.
 2. The round constants columns are populated correctly. Specifically, in rows congruent to $j$ mod 8, `const[i] - round_constants[j⋅m+i]` for `i in [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]`. Note that the round constants are only defined for `j in [0,1,2,3,4]`; in other rows the round constants are unconstrained.
 3. The logarithmic differential columns within each row accumulate the right update. Specifically,
  - `1 + ( γ - a⋅lkin[4⋅i+j+1] - b⋅lkout[4⋅i+j+1] ) ⋅ ( ldh[4⋅i+j] - ldh[4⋅i+j+1] )` for `j in [0,1,2,3]` and `i in [0,1,2]`.
  - `1 + ( γ - a⋅lkin[4⋅(i+1)] - b⋅lkout[4⋅(i+1)] ) ⋅ ( ldh[4⋅i+3] - ldh[4⋅(i+1)] )` for `i in [0,1,2]`.
 4. In padding rows, the state is zero:
  - `pad ⋅ lkin[4⋅i+j]` for `i in [0,1,2,3]` and `j in [0,1,2,3]`;
  - `pad ⋅ lkout[4⋅i+j]` for `i in [0,1,2,3]` and `j in [0,1,2,3]`;
  - `pad ⋅ st[i]` for `i in [4,5,6,7,8,9,10,11,12,13,14,15]`.
 5. The lookup-inputs represent valid field elements – specifically, if the high limbs are all ones, then the low limbs must be all zeros. `(1 - (lkin[4i]-65535) ⋅ (lkin[4i+1]-65535) ⋅ lkininv[i]) ⋅ (lkin[4i+2] + lkin[4i+3])` for `i in [0,1,2,3]`.

*Transition constraints.*

 1. In non-padding rows congruent to 0, 1, 2, 3, or 4 mod 8, the round function is applied. Specifically, 
  - let `s[i] = sum(lkout[4⋅i+j] ⋅ (256^j) for all j in [0,1,2,3])` for `i in [0,1,2,3]`;
  - let `t[i] = st[i+4]^7` for `i in [0,1,2,3,4,5,6,7,8,9,10,11]`;
  - let `subst = s[0] || s[1] || s[2] || s[3] || t[0] || t[1] || t[2] || t[3] || t[4] || t[5] || t[6] || t[7] || t[8] || t[9] || t[10] || t[11] || t[12]`;
  - let `st*[i] = sum(lkin*[4⋅i+j] for j in [0,1,2,3])` for `i in [0,1,2,3]`;
  - then `(1 - pad) ⋅ (sum(MDS[i][j] ⋅ subst[j] for all j) + const[i] - st*[i])` for `i in [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]`.
 2. In rows congruent to 5 or 6 mod 8, the state does not change. Specifically:
  - `lkin[4⋅i+j] - lkin*[4⋅i+j]` for all `i in [0,1,2,3]` and `j in [0,1,2,3]`
  - `lkout[4⋅i+j] - lkout*[4⋅i+j]` for all `i in [0,1,2,3]` and `j in [0,1,2,3]`
  - `st[i] - st*[i]` for all `i in [4,5,6,7,8,9,10,11,12,13,14,15]`.
 3. In rows congruent to 7 mod 8, the next state is unconstrained. (This does not give rise to any constraints.)
 4. The first logarithmic derivative of the next row updates the last logarithmic derivative from the current row and integrates the right update: `1 + ( γ - a⋅lkin*[0] - b⋅lkout*[0] ) ⋅ ( ldh[15] - ldh*[0] )`.

 *Terminal constraints.* None.

### Cascade Table

The cascade table has 5 base columns and 3 extension columns. They are:

 - `lkinhi`, `lkinlo` (base) are the high and low limbs of the input;
 - `lkouthi`, `lkoutlo` (base) are the high and low limbs of the output;
 - `mul` (base) is the multiplicity with which the current row is being queried;
 - `ldhi` and `ldlo` (extension) are the running logarithmic derivative columns for the high and low pairs, respectively;
 - `sum` (extension) is the running sum of inverses.

Additionally, column `pad` indicates whether a given row is a padding row.

*Initial constraints.*

 1. If the first row is not padding, the sum of inverses column starts off having accumulated the term associated with the first row; otherwise this sum is zero. `pad ⋅ (sum ⋅ (γ - a ⋅ lkinhi ⋅ 2^8 - a ⋅ lkinlo - b ⋅ lkouthi ⋅ 2^8 - b ⋅ lkoutlo) - mul) + (1-pad) ⋅ sum`.
 2. If the first row is not padding, the high limb logarithmic derivatives starts off having integrated the first update; otherwise it starts off set to zero.
   - `pad ⋅ (ldhi ⋅ (β - c ⋅ lkinhi - d ⋅ lkouthi) - 1) + (1-pad) ⋅ ldhi`

*Consistency constraints.*

 1. The padding indicator is a bit: `pad ⋅ (1 - pad)`.
 1. If the row is not padding, the low limb logarithmic derivative updates the high limb one; otherwise no update. `pad ⋅ ((ldhi - ldlo) ⋅ (β - c⋅lkinlo - d⋅lkoutlo) + 1) + (1-pad) ⋅ (ldhi - ldlo)`

*Transition constraints.* If the new row is not padding, the high limb logarithmic derivative updates the low limb one from the previous row; otherwise no update. `pad* ⋅ ((ldlo - ldhi*) ⋅ (β - c*lkinhi* - d*lkouthi*) + 1) + (1-pad*) ⋅ (ldlo - ldhi*)`

*Terminal constraints.* None.
  
### Lookup Table

To establish the correct contents of the Lookup Table, it suffices to compute one running evaluation in an extension column `re`. As there are only 256 elements of the table and as all are known to the verifier, the verifier can compute the terminal value of this running evaluation locally. This construction gives rise to one initial constraint, one transition constraint, and one terminal constraint.

More specifically, there are 6 columns:
 - base column `lkin` and `lkout` contain the input-output pairs;
 - base column `mul` contains the multiplicity with which it is being looked up;
 - base column `pad` indicates whether the row is padding or not;
 - extension column `re` contains the running evaluation for proving the correct input-output pairs;
 - extension column `sum` contains the running sum of inverses.

*Initial constraints.* 

 1. The running evaluation starts off having accumulated the first term: `re - δ + c⋅lkin + d⋅lkout`.
 2. The running sum of inverses starts off having accumulated the first row: `mul - (β - c⋅lin - d⋅lout) ⋅ sum`.

*Consistency constraints.*

 1. The padding indicator is a bit: `pad ⋅ (1 - pad)`.
 2. The input and output are set to zero in padding rows: `lkin ⋅ pad` and `lkout ⋅ pad`.
 3. The multiplicity is zero in padding rows: `mul ⋅ pad`.

*Transition constraints.*

 1. The running evaluation accumulates one term in every non-padding row, and remains in padding rows: `(β⋅re + a⋅lin* + b⋅lout* - re*) ⋅ (1 - pad) + (re - re*) ⋅ pad`.
 2. The running sum of inverses accumulates one update in every non-padding row, and remains in padding rows: `(pad - 1) ⋅ (mul* + (γ - a⋅lin* - b⋅lout*) ⋅ (sum - sum*)) + pad ⋅ (sum - sum*)`.

*Terminal constraints.*

 1. The `(lin,lout)` pairs are correct. To verify this, let $B = \sum_{i=0}^{255} (a \cdot i + b \cdot L(i)) \cdot \delta^{255-i}$ be computed locally by the verifier via the recursive Horner relation $B_0 = 0$ and $B_{n+1} = \delta \cdot B_n + a \cdot n + b \cdot L(n)$ such that $B_{255} = B$. Then the terminal constraint is `re - B`.

### Cross-Table Constraints

With the above columns and AIR constraints, the remaining piece of the entire cascading lookup argument is two cross-table constraints, both of which equate the logarithmic derivative to the running sum. Between the hash table and the cascade table this is `ldh[15] - sum`. Between the cascade table and the lookup table this is `ldlo - sum`.

### Summary

The next table gives an overview of the base and extension column used in the various tables.

| Table     | base | extension | sum | B-field equivalent sum |
|-----------|------|-----------|-----|-----|
| Hash      | 49   | 16        | 65  |  97 |
| Cascade   | 6    | 3         | 9   |  15 |
| Lookup    | 4    | 2         | 6   |  10 |
| **Total** | 59   | 21        | 80  | 122 |


### Comparison to Rescue-Prime Optimized

To make an apples-to-apples comparison we restrict the degree of the AIR to two, and add columns as necessary.

For Tip5 this means we have to add 3 columns per state element that undergoes the forward $\alpha$ th power map. The first contains the square, the second the fourth power, the third the sixth power; the seventh power is used directly in the transition constraint since it is now quadratic. Accordingly, this induces 3 new consistency constraints. There are 12 columns that need to be expanded in this way. So the total number of base columns is 55 + 3⋅12 = 91. The total number of columns is then 112 technically or 154 in B-field equivalents.

For Rescue-Prime and Rescue-Prime Optimized there are 16 columns that need to be expanded in this way.The total number of base columns is 16 + 16⋅3 = 64. The total number of columns is the same, 64, whether in technical terms of B-field equivalent terms.

Note that for the parameters here, Rescue-Prime has 8 rounds and as a result the trace of one hash function invocation does not fit into 8 rows. To accomodate for this, one must either include columns for counting the round, or expand the trace into 16 rows and use periodic constraints or periodic interpolants.

## Performance

These benchmarks were obtained on a Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz. On this machine Tip5 is 12.19× faster than Rescue-Prime Optimized. The implementation is available at [10].

| Hash Function          | time      |
|------------------------|-----------|
| Rescue-Prime           | 18.186 µs |
| Rescue-Prime Optimized | 14.357 µs |
| Tip5                   | 1.1776 µs |

## Security

### Statistical Differential Attack

The MDS matrix guarantees that in every consecutive pair of rounds, at least $m+1$ S-boxes are differentially active. But in every consecutive pair of rounds, there are only $2s$ split-and-lookup maps, so at least $m+1-2s$ forward $\alpha$-th power map must be differentially active. The probability that a differential characteristic is satisfied across two rounds is therefore at most $\left( \frac{\alpha - 1}{p} \right)^{m+1-2s}$. For the given parameters this probability is smaller than $2^{-552}$.


### Gröbner Basis Attacks

There are $m(N+1)$ wires of which $c$ are set to zero initially and $d$ are given by the digest, so $m(N+1)-c-d$ in total. There are as many equations. Their degrees are

 1. $p-1$ (or close to $p-1$) if it describes a split-and-lookup map;
 2. $\alpha$ if it describes a forward $\alpha$-th power map.

The Macaulay bound exceeds $p$. Therefore it pays to add the field equation $x^p - x$ for every variable $x$. This addition has the effect of restricting the degree to $p-1$ in every variable.

Macaulay matrix at this degree has $\binom{p-1}{m(N+1)-c-d}$ columns and as many rows. Assuming that the matrix is dense, finding a kernel vector using sparse linear algebra methods takes this number *squared* operations. For one round and setting the other parameters as above, this square is approximately equal to $2^{2557}$.

### Linear Approximation

The complexity of a Gröbner basis attack drops dramatically if the split-and-lookup maps are replaced with their best linear approximations. The resulting solution represents a successful attack (i.e., a (second) preimage or a collision) if it happens to coincide with the variety of the exact system of polynomials, i.e., without approximations. By modeling the solution found via polynomial system solving as a random element from the approximate variety, it is possible to estimate the probability that it lives also in the exact variety. Specifically: we count the number of approximate maps and the number of points they agree with their targets in.

One linear approximation to the split-and-lookup map agrees in 240 points, corresponding to the 2 fixed points of $L$, repeated 8 times, except for 16 values that can't be reached because they correspond to 64-bit integers greater than $p$. Inside 1 round there are $s$ split-and-lookup maps and the probability that they all send one of these agreeable points to their correct destination is $\left(\frac{240}{p}\right)^s$. For the given parameters this probability is less than $2^{-224}$ in one round. In other words, if we were to attack a single round with this technique, the produced solution would be correct (i.e., a valid (second) preimage or collision) with this probability.

Barring cancellations of approximation errors, and assuming that the state vectors are independent and uniform before they enters into a round, the probability of correct approximation drops exponentially in the number of rounds. Excluding the first and last round one estimates this probability at $\left(\frac{240}{p}\right)^{(N-2)s} \approx 2^{-1120}$. 

### Fixing

Another technique to leverage Gröbner basis techniques consists of fixing at random the values on the wires into and out from the split-and-lookup S-boxes. Where the standard polynomial model of the cipher consists of high degree polynomials but as a system of equations has degree but $r-d = 5$ degrees of freedom (assuming preimage search); after fixing it consists of low degree polynomials but $r-d-Ns = -15$ degrees of "freedom". A random system of equations with this degree of over-determinedness can be expected to have a solution with probability on the order of $p^{-15} \approx 2^{960}$.

## Test Vectors

### Fixed-Length Hashing

```
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0] -> [6277536787940266635, 113813570434641399, 3176428054993699128, 7643709797287858368, 16186647325996799146]
[6277536787940266635, 113813570434641399, 3176428054993699128, 7643709797287858368, 16186647325996799146, 0, 0, 0, 0, 0] -> [12868664103968790786, 5525189745185563828, 5315847067049072973, 16539568969275610931, 6980395927134919557]
[6277536787940266635, 12868664103968790786, 5525189745185563828, 5315847067049072973, 16539568969275610931, 6980395927134919557, 0, 0, 0, 0] -> [17841590213364219328, 15916556071415617773, 13462310052037670832, 3800469511547463241, 7001571953711459824]
[6277536787940266635, 12868664103968790786, 17841590213364219328, 15916556071415617773, 13462310052037670832, 3800469511547463241, 7001571953711459824, 0, 0, 0] -> [17033535751861257877, 12906717896520464746, 8551294288075183248, 12159951975931385497, 11166840847903321578]
[6277536787940266635, 12868664103968790786, 17841590213364219328, 17033535751861257877, 12906717896520464746, 8551294288075183248, 12159951975931385497, 11166840847903321578, 0, 0] -> [6125535662360392812, 673236592617824778, 7557131128963852994, 8509287281737226151, 12419037257076928507]
[6277536787940266635, 12868664103968790786, 17841590213364219328, 17033535751861257877, 6125535662360392812, 673236592617824778, 7557131128963852994, 8509287281737226151, 12419037257076928507, 0] -> [12173977354378450251, 17246361511264214833, 11175337653003594563, 2476965045993113840, 13164967615365715689]
[6277536787940266635, 12868664103968790786, 17841590213364219328, 17033535751861257877, 6125535662360392812, 12173977354378450251, 17246361511264214833, 11175337653003594563, 2476965045993113840, 13164967615365715689] -> [11624820369960046983, 9870887832019477602, 9889124322496704709, 16025862226051106532, 8482740071231775635]
```

### Variable-Length Hashing

```
[] -> [11739145755412463878, 11158747312363548374, 433104918313849317, 18037100479724399373, 821702010089335966]
[0] -> [4901730926848294727, 1836518579096186188, 5347422372214504859, 9464701735067958238, 10660807409690599479]
[0, 1] -> [4883131253638084304, 13780543268781298797, 6167300186458575316, 17155423243054686047, 11092023301371062636]
[0, 1, 2] -> [9486955229791153219, 1597140181201965540, 3242129245478489210, 13159420919759627750, 11228195023800918194]
[0, 1, 2, 3] -> [486487223200900598, 1139232066649080153, 12651847494613759389, 5187142265314146122, 3316641302241093221]
[0, 1, 2, 3, 4] -> [15905878262251877312, 12620746577526449799, 12869579473534565075, 12482910554201719841, 9022234382365531307]
[0, 1, 2, 3, 4, 5] -> [13668115959918647227, 13102277416109525633, 13907197421264876758, 830289992753072486, 7588871991158071661]
[0, 1, 2, 3, 4, 5, 6] -> [10276852122147465323, 10556504602198264375, 1331968256992188487, 5804265351017323254, 3757662523680629745]
[0, 1, 2, 3, 4, 5, 6, 7] -> [16674293860940515406, 3327132363906545705, 17297979635106786157, 5558816184085890478, 11816405595240671921]
[0, 1, 2, 3, 4, 5, 6, 7, 8] -> [10938610991537130300, 9782579423255975313, 13854249281349329726, 18045308750647398614, 17295736510552378802]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] -> [9618553696906066663, 14723961024302607630, 5465770264274162547, 9178411239256724919, 4847409776424769425]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] -> [45623424055279858, 10184022748613869352, 15248301819882448767, 14119016512548259853, 2178108698842369171]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11] -> [16880977297917961990, 5105651618378944860, 12851841401382126897, 1836281673129252321, 7342477101360280652]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] -> [15616235328192010501, 17517112492252320735, 13668198895944996401, 12440011522509312715, 9080296100326223839]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] -> [7433985916565204408, 12937836458291950527, 3634916753417313828, 17832068202056474990, 15180872870689215640]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14] -> [6507845225608937077, 6668745795536911303, 15674386097745529713, 11888858352837642787, 4952747613431863276]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15] -> [11704816762985694367, 12775283418675937623, 10021502601748679227, 9623857610977416310, 7269902620283828234]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16] -> [8674690629994437392, 4688122681233803802, 2185964052266177589, 783332892951567901, 4947832873065849294]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17] -> [15345722914026746307, 15476866851770564565, 14160918454236920715, 7796563515198114850, 16784756722999101071]
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18] -> [2154652293143361367, 13411775419828505579, 6889656282700149480, 5361506924111201878, 14236977948361285105]
sum of digests: [8476864380936389014, 7923359605828412643, 2436794214779586248, 12117847227056347517, 7400965751243819750]
```

## References

[1]: https://www.iacr.org/cryptodb/data/paper.php?pubkey=3167
[2]: https://eprint.iacr.org/2019/426
[3]: https://eprint.iacr.org/2020/1143
[4]: https://eprint.iacr.org/2021/1038
[5]: https://eprint.iacr.org/2020/315
[6]: https://eprint.iacr.org/2022/1577
[7]: https://eprint.iacr.org/2022/1530
[8]: https://eprint.iacr.org/2022/274
[9]: https://eprint.iacr.org/2016/504
[10]: https://github.com/Neptune-Crypto/twenty-first/blob/master/twenty-first/src/shared_math/tip5.rs