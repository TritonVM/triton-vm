# TIP 0009: Polynomial Acceleration

| TIP            | 0009                                             |
|:---------------|:-------------------------------------------------|
| authors:       | Alan Szepieniec                                  |
| title:         | Polynomial Acceleration                          |
| status:        | draft                                            |
| created:       | 2024-01-18                                       |
| issue tracker: | <https://github.com/TritonVM/triton-vm/pull/219> |

**Abstract** This note describes an improvement to Triton VM (or STARK VMs in general)
whereby the VM can perform arithmetic operations on polynomials in addition to operations on field elements. The correct evolution of the values contained by polynomial-registers is ensured through an AIR constraint system collapsing the polynomials in question to their evaluations in a random point supplied by the verifier. Extending the power of polynomial arithmetic to the VM has the potential to reduce the cost of key steps in the context of recursive verification and other complex tasks, such as
 - the low degree test of an explicit codeword;
 - the verification of the correct evaluation of a circuit;
 - continuations, enabling the segmentation of a long-winded computation into segments that can be proven separately before being joined through recursion;
 - single-instruction multiple-data instructions in general;
 - the verification of a number-theoretic transform;
 - big-integer operations.

# Introduction

The STARK proof system traditionally certifies the correct evolution of a set of registers
by reducing the satisfaction of the AIR constraints (that define what "correct evolution"
means) on a given domain of interest, to a clean division of polynomials. Two features of this description are
noteworthy, First, the values these registers can take live in a *finite field*. Second, the
AIR constraints are *local*: they relate all tuples of states with an distance
pattern that is both static and independent of the total evolutionary length -- typically:
pairs of consecutive states.

To overcome the limitation of locality, it suffices to define another trace which
contains or pertains to the same underlying data but differs in terms
of its dimension of evolution. The different dimensions of evolution, e.g., time versus
address space, induce different notions of locality, which can be captured by different 
distance patterns and thus different AIR constraints.

A round of interaction with the verifier suffices to establish the correct relation
between the two *a priori* distinct traces. The verifier supplies randomness, which is 
then used to populate additional auxiliary columns in the trace whose purpose is to
capture some aggregate quantity. Auxiliary AIR constraints certify the correct values in
these auxiliary columns. The Schwartz-Zippel lemma bounds the probability that the 
matching aggregate quantities of two distinct traces agree despite originating from disparate data sets.

In this note we analyze the first noteworthy feature. Phrased as a limitation to be overcome,
the question becomes: *what other values can registers take, beyond finite field elements?*

This note supplies an answer: *univariate polynomials over the finite field*.

Intuitively,
the virtual machine gets symbolic access to the randomness that will be sampled by the 
verifier. Since the virtual machine does not know the value of this symbol, any arithmetic
done on it must be represented symbolically â€“ in the form of a polynomial or a circuit.

While the AIR constraints could in principle be lifted from a circuit whose inputs are
field elements to a circuit whose inputs are polynomials, the point of composing the AIR
with the interpolants of the trace is to obtain univariate polynomials which are then
proven to have  low degree using FRI. If the AIR is lifted to take univariate polynomials,
this composition will result in bivariate polynomials for which no low degree test is
known.

Therefore, instead of lifting the AIR, the symbolic polynomials are collapsed using 
evaluation in a random point supplied by the verifier. Now the AIR applies, as usual, to a
vector of field elements.

Extending a virtual machine architecture with polynomial arithmetic presents a number of
challenges. 

 - A typical set of instructions include instructions that are not friendly to
   polynomials, such as range-checks or hashing; these instructions must be barred somehow
   from applying to polynomials.
 - A typical architecture layout consists of several independent logical units that
   communicate data to one another. This communication channel must either disallow 
   the transmission of polynomials or all logical units that are party to it must support
   them. 
 - In order to justify using the Fiat-Shamir transform, there must be enough entropy in
   the first message sent by the prover, which commits to the part of the trace that is
   independent of the polynomials.
 - An obvious primitive to be supported in the context of univariate polynomials is
   testing their low degree. Including a dynamic number of dynamically-defined polynomials
   in the FRI low degree test raises questions regarding soundness.

To address these challenges this note suggests to contain all polynomial arithmetic within
a single logical unit called the *Univariate Polynomial Coprocessor (UPC)*. Specifically,
this note suggests a concrete architecture for this coprocessor and concrete integration
with the rest of the architecture of Triton VM.

# Architecture

## High-Level Perspective

The proposed change introduces a new arithmetic/logical unit called the UPC. Conceptually the new unit is distinct from the processor but from the point of view of arithmetization it may be merged into the same table. There is no need to expand a single cycle or row on the processor into multiple cycles or rows on the univariate polynomial coprocessor, and merging the two tables has the additional benefit of obviating the communication bus that would otherwise be needed.

The UPC consists of 3 + 1 + 2*(`NUM_POLYNOMIAL_REGISTERS` + 2) + 1 + 5 registers, divided into four groups:
 1. Register indicators.
   - `lhs` the left-hand-side of the polynomial operation, indicating a polynomial register
   - `rhs` the right-hand-side of the polynomial operation, indicating a polynomial register
   - `dest` the destination of the polynomial operation, indicating a polynomial register
 2. Low degree accumulator. This registers serves to prove the low degree of polynomials that arise in the course of some computation. 
   - `acc` is a *bivariate* polynomial (in $X$ and $Y$) over the *extension field* that accumulates one univariate polynomial (in $X$) every time a new polynomial arises whose low degree must be proven. Specifically, every time a new polynomial $f(X)$ arises, this register is modified as $\mathtt{acc} \mapsto Y \cdot \mathtt{acc} + f(X)$. Conceptually, the purpose of the variable $Y$ is to collapse a bunch of univariate polynomials in $X$ into one random linear combination. The AIR constraints guarantee that $\mathsf{acc}(X,\beta)$ is updated correctly in every row.
 3. Polynomial registers. In the first round of interaction, these registers take values from the univariate polynomial ring (in $X$) over the *base* field. In the second round of interaction, these registers take values from the extension field as these polynomials are collapsed to their evaluation in $\alpha$.
   - `pr0`
   - ...
   - `prn` where `n = NUM_POLYNOMIAL_REGISTERS-1`.
 4. Produce. These registers hold up to two result-values which live in the univariate ring over the *extension field*.
   - `res0`
   - `res1`.
 5. Degree trackers. For the register and produce polynomials it is necessary to track their degrees. We do this with a register that contains the monomial $X^{-d}$, where $d$ is the polynomial's degree bound.
   - `pr0_deg`
   - ...
   - `prn_deg`
   - `res0_deg`
   - `res1_deg`.
 6. Degree tracker holder. This register is necessary only to hold the quotient of one degree tracker by another. The two constraints that enforce this relation cannot be algebraically eliminated.
   - `ddiv`
 7. Acculumator polynomial segments. These five columns store segment codewords of the final value of the accumulator polynomial $\mathsf{acc}_{T-1}(X,\beta)$. The word "segment" is used in the same sense as "segmentation polynomial" the random linear combination of quotients after dividing out zerofiers which, if its degree is $kN$, must be represented across $k$ columns.
  - `acc_seg0`
  - ...
  - `acc_seg4`.

The indeterminates $X$ and $Y$ are symbolic values and the polynomials in them are represented symbolically. The first round of interaction involves the prover committing to the scalar part of the AET and the verifier sampling $\beta$. After the first round, $Y$ is substituted for $\beta$. The second round involves the prover committing to the part of the AET that becomes scalar under this substitution, which is the accumulator polynomial segments, and the verifier sampling $\alpha$ in response. After this round, the prover substitutes $X$ for $\alpha$ and commits to the remainder of the AET. Note that this construction has one more stage than traditional STARKs do.

The reason why the accumulation of intermediate results into `acc` certifies that they are indeed low degree is because the univariate polynomial $\mathtt{acc}(X, \beta)$ represents a random linear combination of all accumulated polynomials, weighted by powers of $\beta$. This univariate polynomial corresponds to five segmentation codewords, which are included in the linear combination of codewords that goes into FRI.

The five segmentation codewords produce two out-of-domain rows. The first out-of-domain row represents their evaluation in $\alpha$ and the second in $\gamma$ (which is the out-of-domain point it has in common with the rest of the AET). These segment codewords undergo two DEEP updates. The first certifies that they do agree with the out of domain row corresponding to $\alpha$; and the second DEEP update is the same old DEEP-ALI technique that is applied to one big random linear sum of both out-of-domain points and codewords. The verifier combines the $\alpha$ out-of-domain row to obtain $\mathsf{acc}(\alpha,\beta)$, which is needed to enforce the terminal constraint on `acc`.

## Instructions

The following instructions make use of the univariate polynomial coprocessor. The involved registers are indicated by the instruction argument, which in the general case can take values from `0` to `NUM_POLYNOMIAL_REGISTERS^3 - 1`.

 - `poly_add` adds two polynomials and stores the result.
 - `poly_mul` multiplies two polynomials and stores the result.
 - `poly_div` performs long division on two polynomials and stores the quotient.
 - `poly_mod` performs long division on two polynomials and stores the remainder.
 - `poly_eval` evaluates a polynomial in a given (by the opstack) extension field element and returns (to the processor) the result.
 - `poly_copy` copies a polynomial from one register to another.
 - `poly_shift` multiplies a polynomial by some power of $X$.
 - `poly_assemble` assembles a polynomial out of the few opstack elements by interpreting them as coefficients, and stores the result.
 - `poly_asa` assembles one polynomial, and adds it to the shift of another.

For brevity we focus on only on the mechanics of `poly_mod` as the other instructions are either similar or simple enough to exempt from explicit treatment.

The instruction `poly_mod` takes an immediate argument which decomposes into three indices of polynomial registers, respectively the two inputs and the output of the operation. Let $n(X)$ and $d(X)$ denote the polynomials contained by the indicated inputs and let $n_d(X) = X^{-b_n}$ and $d_d(X) = X^{-n_d}$ be their degree trackers. The registers `res0` and `res1` are populated with the polynomials $q(X)$ and $r(X)$ (whose degree trackers are $q_d(X) = X^{-b_q}$ and $r_d(X) = X^{-b_r}$) such that $n(X) = q(X) \cdot d(X) + r(X)$ and such that $\deg(q) \leq \deg(n)$ and $\deg(r) < \deg(d)$. The result $r(X)$ is copied from `res1` to the indicated register. Into `acc` are accumulated with successive powers of $Y$ as coefficients:
 - `res0`
 - `res1`
 - $X^N \cdot$ `res0_deg` â‹… `res0`
 - $X^N \cdot$ `res1_deg` â‹… `res1`
 - `res1_deg` â‹… `prn_deg`$^{-1}$ where `prn_deg` denotes the degree tracker indicated by `lhs`.

Specifically, the AIR constraint for `acc` is:

```
res0 + Î² res1 + Î²^2 â‹… Î±^N â‹… res0_deg â‹… res0 + Î²^3 â‹… Î±^N â‹… res1_deg â‹… res1  + Î²^4 â‹… res1_deg â‹… prn_deg^-1 + Î²^5 â‹… acc - acc* = 0
```

The verifier computes $X^N$ locally. Computing this value is cheap because he knows $N$: it is one more than the max degree of the FRI low-degree test. Also, the value `res1_deg` â‹… `prn_deg`$^{-1}$ is what is stored in `ddiv`.

The equality $n(X) = q(X) \cdot d(X) + r(X)$ gives rise to a single AIR constraint. The degree bounds $0 \leq \deg(q) \leq \deg(n)$ and $0 \leq \deg(r) < \deg(d)$ require special attention. They are enforced indirectly, by using degree trackers as an intermediate step. The indirection is motivated by the clean division that degree trackers give rise to.

Then the conditions $\{ 0 \leq \deg(q) \leq \deg(n)$ , $0 \leq \deg(r) < \deg(d) \}$ follow from any $\{n_d(X), d_d(X), q_d(X), r_d(X)\}$ with the following set of conditions:
 - $0 \leq \deg(q)$
 - $\deg(q) \leq \deg(q_d)$
 - $\deg(q_d) \leq \deg(n_d)$
 - $\deg(n_d) \leq \deg(n)$
 - $0 \leq \deg(r)$
 - $\deg(r) \leq \deg(r_d)$
 - $\deg(r_d) + 1 = \deg(d_d)$ or $r = 0$
 - $\deg(d_d) \leq \deg(d)$

Note that the conditions $\deg(n_d) \leq \deg(n)$ and $\deg(d_d) \leq \deg(d)$ may be assumed to be true as these degree trackers are established by the previous cycle.

The remaining conditions are enforced as follows (in unlinked order):

 1. $\deg(q_d) \leq \deg(n_d)$. Storing the value $q_d(X) / n_d(X) = X^{n_q - q_n}$ in `ddiv` induces two constraints, in addition to the contribution to $\mathsf{acc}(X,Y)$ already listed above:
   - `(prn_deg â‹… ddiv - res1_deg) â‹… prn_deg = 0`
   - `(prn_deg â‹… ddiv - res1_deg) â‹… ddiv = 0`.
 2. $\deg(r_d) + 1 = \deg(d_d)$ or $r = 0$. This proposition gives rise to one AIR constraint: `(res0_deg - Î± â‹… prd_deg) â‹… res0` and no contributions to $\mathsf{acc}(X,Y)$.
 3. $\deg(q) \leq \deg(q_d)$. This proposition gives rise to a contribution $X^N \cdot X^{-b_q} \cdot q(X)$ to $\mathsf{acc}(X,Y)$. Note that if the condition is false then the contribution to $\mathsf{acc}(X,Y)$ has degree $\geq N$ causing FRI to fail.
 4. $\deg(r) \leq \deg(r_d)$. This proposition gives rise to a contribution $X^N \cdot X^{-b_r} \cdot r(X)$ to $\mathsf{acc}(X,Y)$, which has degree $<N$ only if the condition is satisfied.
 5. $0 \leq \deg(q)$ gives rise to contribution (already listed above) of $q(X)$ to the polynomial $\mathsf{acc}(X,Y)$.
 6. $0 \leq \deg(r)$ gives rise to contribution (also already listed above) $r(X)$ to the polynomial $\mathsf{acc}(X,Y)$.

Lastly, it is important to ensure the the degree tracker for the resulting value is correct as well. This gives rise to two AIR constraints, one for the remainder and one for the quotient:
 - `res0_deg - prd_deg = 0`
 - `res1_deg â‹… prd_deg - ddiv = 0`.

# Applications

## Fri Last Round

## Big Integer Arithmetic

## Repeated Circuit Evaluations

